{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b631d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar 29 21:26:38 2022\n",
    "\n",
    "@author: Shangchen\n",
    "\"\"\"\n",
    "import multiprocessing as mp\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def colnames(x):\n",
    "    if not isinstance(x, pd.core.frame.DataFrame):\n",
    "        raise Exception(\"Input is not pandas.core.frame.DataFrame \")\n",
    "    return x.columns.to_numpy(dtype=\"U\")\n",
    "\n",
    "\n",
    "def ncol(x):\n",
    "    if not isinstance(x, pd.core.frame.DataFrame):\n",
    "        raise Exception(\"Input is not pandas.core.frame.DataFrame \")\n",
    "    return len(x.columns)\n",
    "\n",
    "\n",
    "def nrow(x):\n",
    "    if not isinstance(x, pd.core.frame.DataFrame):\n",
    "        raise Exception(\"Input is not pandas.core.frame.DataFrame \")\n",
    "    return len(x.index)\n",
    "\n",
    "\n",
    "def colSums(x):\n",
    "    if not isinstance(x, pd.core.frame.DataFrame):\n",
    "        raise Exception(\"Input is not pandas.core.frame.DataFrame \")\n",
    "    return x.sum(axis=0)\n",
    "\n",
    "\n",
    "def rowSums(x):\n",
    "    if not isinstance(x, pd.core.frame.DataFrame):\n",
    "        raise Exception(\"Input is not pandas.core.frame.DataFrame \")\n",
    "    return x.sum(axis=1)\n",
    "\n",
    "\n",
    "def r_in(x, y):\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    return np.array([np.isin(item, y) for item in x]).astype(bool)\n",
    "\n",
    "\n",
    "def r_ni(x, y):\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    return np.array([not np.isin(item, y) for item in x]).astype(bool)\n",
    "\n",
    "\n",
    "def rm(*args):\n",
    "    del args\n",
    "\n",
    "\n",
    "def slice_bool(x, y):\n",
    "    \"\"\"Slicing list by a boolean list\"\"\"\n",
    "    return list(compress(x, y))\n",
    "\n",
    "\n",
    "def inv_bool(x):\n",
    "    return [not i for i in x]\n",
    "\n",
    "\n",
    "def cbind(x):\n",
    "    return pd.concat(x, axis=1)\n",
    "\n",
    "\n",
    "def which(x):\n",
    "    return np.array([i for i, j in enumerate(x) if j])\n",
    "\n",
    "\n",
    "def np_assign_but(ar, but_ind, v):\n",
    "    assign_ind = np.setdiff1d(np.arange(len(ar)), but_ind)\n",
    "    ar[assign_ind] = v\n",
    "    return\n",
    "\n",
    "\n",
    "def IFAA(\n",
    "    MicrobData,\n",
    "    CovData,\n",
    "    linkIDname,\n",
    "    testCov=np.empty(0),\n",
    "    ctrlCov=np.empty(0),\n",
    "    testMany=True,\n",
    "    ctrlMany=False,\n",
    "    nRef=40,\n",
    "    nRefMaxForEsti=2,\n",
    "    refTaxa=np.empty(0),\n",
    "    adjust_method=\"fdr_by\",\n",
    "    fdrRate=0.15,\n",
    "    paraJobs=np.empty(0),\n",
    "    bootB=500,\n",
    "    standardize=False,\n",
    "    sequentialRun=False,\n",
    "    refReadsThresh=0.2,\n",
    "    taxkeepThresh=1,\n",
    "    SDThresh=0.05,\n",
    "    SDquantilThresh=0,\n",
    "    balanceCut=0.2,\n",
    "    seed=1,\n",
    "):\n",
    "\n",
    "    testCov = np.array(testCov)\n",
    "    ctrlCov = np.array(ctrlCov)\n",
    "    linkIDname = np.array(linkIDname)\n",
    "    refTaxa = np.array(refTaxa)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"Time: \", stop - start)\n",
    "    runMeta = metaData(\n",
    "        MicrobData=MicrobData,\n",
    "        CovData=CovData,\n",
    "        linkIDname=linkIDname,\n",
    "        taxkeepThresh=taxkeepThresh,\n",
    "        testCov=testCov,\n",
    "        ctrlCov=ctrlCov,\n",
    "        testMany=testMany,\n",
    "        ctrlMany=ctrlMany,\n",
    "    )\n",
    "\n",
    "    data = runMeta[\"data\"]\n",
    "    results[\"covariatesData\"] = runMeta[\"covariatesData\"]\n",
    "    binaryInd = runMeta[\"binaryInd\"]\n",
    "    covsPrefix = runMeta[\"covsPrefix\"]\n",
    "    Mprefix = runMeta[\"Mprefix\"]\n",
    "    testCovInd = runMeta[\"testCovInd\"]\n",
    "    testCovInOrder = runMeta[\"testCovInOrder\"]\n",
    "    testCovInNewNam = runMeta[\"testCovInNewNam\"]\n",
    "    ctrlCov = runMeta[\"ctrlCov\"]\n",
    "    microbName = runMeta[\"microbName\"]\n",
    "    newMicrobNames = runMeta[\"newMicrobNames\"]\n",
    "    results[\"covriateNames\"] = runMeta[\"xNames\"]\n",
    "    del runMeta\n",
    "\n",
    "    if (refTaxa is not None) and (len(refTaxa) > 0):\n",
    "        if sum(r_in(refTaxa, microbName)) != len(refTaxa):\n",
    "            raise Exception(\n",
    "                \"\"\"\n",
    "                             Error: One or more of the specified reference taxa in phase 1 have no sequencing reads \n",
    "                             or are not in the data set. Double check the names of the reference taxa and their \n",
    "                             sparsity levels.\"\"\"\n",
    "            )\n",
    "    if nRefMaxForEsti < 2:\n",
    "        nRefMaxForEsti = 2\n",
    "        warnings.warn(\n",
    "            \"Warning: Needs at least two final reference taxon for estimation.\"\n",
    "        )\n",
    "\n",
    "    if nRef > len(microbName):\n",
    "        raise Exception(\n",
    "            \"Error: number of random reference taxa can not be larger than the total number of taxa in the data. Try lower nRef\"\n",
    "        )\n",
    "\n",
    "    refTaxa_newNam = newMicrobNames[r_in(microbName, refTaxa)]\n",
    "\n",
    "    results[\"analysisResults\"] = Regulariz(\n",
    "        data=data,\n",
    "        testCovInd=testCovInd,\n",
    "        testCovInOrder=testCovInOrder,\n",
    "        testCovInNewNam=testCovInNewNam,\n",
    "        microbName=microbName,\n",
    "        nRef=nRef,\n",
    "        nRefMaxForEsti=nRefMaxForEsti,\n",
    "        binaryInd=binaryInd,\n",
    "        covsPrefix=covsPrefix,\n",
    "        Mprefix=Mprefix,\n",
    "        refTaxa=refTaxa_newNam,\n",
    "        paraJobs=paraJobs,\n",
    "        adjust_method=adjust_method,\n",
    "        fwerRate=fdrRate,\n",
    "        bootB=bootB,\n",
    "        standardize=standardize,\n",
    "        sequentialRun=sequentialRun,\n",
    "        refReadsThresh=refReadsThresh,\n",
    "        SDThresh=SDThresh,\n",
    "        SDquantilThresh=SDquantilThresh,\n",
    "        balanceCut=balanceCut,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "\n",
    "def metaData(\n",
    "    MicrobData,\n",
    "    CovData,\n",
    "    linkIDname,\n",
    "    taxkeepThresh,\n",
    "    testCov=np.empty(0),\n",
    "    ctrlCov=np.empty(0),\n",
    "    testMany=True,\n",
    "    ctrlMany=True,\n",
    "    MZILN=False,\n",
    "):\n",
    "    results = {}\n",
    "    \n",
    "    if not linkIDname:\n",
    "        raise Exception(\"linkIDname is missing.\")\n",
    "\n",
    "    if len(testCov) > 0 and len(ctrlCov) > 0:\n",
    "        if sum(r_in(np.concatenate((testCov, ctrlCov)), colnames(CovData))) != len(\n",
    "            np.concatenate((testCov, ctrlCov))\n",
    "        ):\n",
    "            raise Exception(\"Error: some covariates are not available in the data.\")\n",
    "\n",
    "    if sum(r_in(testCov, ctrlCov)) > 0:\n",
    "        warnings.warn(\n",
    "            \"Variables appeared in both testCov list and ctrlCov list will be treated as testCov.\"\n",
    "        )\n",
    "\n",
    "    # read microbiome data\n",
    "    MdataWithId = MicrobData\n",
    "    if len(colnames(MdataWithId)) != ncol(MdataWithId):\n",
    "        raise Exception(\"Microbiome data lack variable names.\")\n",
    "\n",
    "    if (MdataWithId.loc[:, MdataWithId.columns != linkIDname].values < 0).any():\n",
    "        raise Exception(\"Microbiome data contains negative values.\")\n",
    "\n",
    "    if MdataWithId[linkIDname].isna().mean() > 0.8:\n",
    "        warnings.warn(\n",
    "            \"There are over 80% missing values for the linkId variable in the Microbiome data file. Double check the data format.\"\n",
    "        )\n",
    "\n",
    "    # read covariate data\n",
    "    CovarWithId = CovData\n",
    "    if CovarWithId[linkIDname].isna().mean() > 0.8:\n",
    "        warnings.warn(\n",
    "            \"There are over 80% missing values for the linkId variable in the covariates data file. Double check the data format.\"\n",
    "        )\n",
    "\n",
    "    Covariates1 = CovarWithId.loc[:, CovarWithId.columns != linkIDname]\n",
    "\n",
    "    # determine testCov and ctrlCov\n",
    "    if len(testCov) == 0:\n",
    "        if not testMany:\n",
    "            raise Exception(\n",
    "                \"No covariates are specified for estimating associations of interest.\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"Associations are being estimated for all covariates since no covariates are specified for testCov.\"\n",
    "            )\n",
    "            testCov = colnames(Covariates1)\n",
    "    results[\"testCov\"] = testCov\n",
    "\n",
    "    xNames = colnames(Covariates1)\n",
    "    rm(Covariates1)\n",
    "\n",
    "    if len(ctrlCov) == 0 and ctrlMany:\n",
    "        print(\n",
    "            \"No control covariates are specified, all variables except testCov are considered as control covariates.\"\n",
    "        )\n",
    "        ctrlCov = xNames[r_ni(xNames, testCov)]\n",
    "    ctrlCov = ctrlCov[r_ni(ctrlCov, testCov)]\n",
    "    results[\"ctrlCov\"] = ctrlCov\n",
    "\n",
    "    # merge data to remove missing\n",
    "    CovarWithId1 = CovarWithId[np.hstack([linkIDname, testCov, ctrlCov])]\n",
    "    allRawData = CovarWithId1.merge(MdataWithId, on=linkIDname.tolist()).dropna()\n",
    "    CovarWithId = allRawData.loc[:, r_in(colnames(allRawData), colnames(CovarWithId1))]\n",
    "    Covariates = CovarWithId.loc[:, r_ni(colnames(CovarWithId), [linkIDname])]\n",
    "    rm(CovarWithId1)\n",
    "\n",
    "    if not all(Covariates.apply(lambda a: a.dtype.kind in \"if\")):\n",
    "        raise Exception(\n",
    "            \"There are non-numeric variables in the covariates for association test.\"\n",
    "        )\n",
    "\n",
    "    MdataWithId = allRawData.loc[:, r_in(colnames(allRawData), colnames(MdataWithId))]\n",
    "    Mdata_raw = MdataWithId.loc[:, r_ni(colnames(MdataWithId), linkIDname)]\n",
    "    rm(allRawData)\n",
    "\n",
    "    # check zero taxa and subjects with zero taxa reads\n",
    "    numTaxaNoReads = sum(colSums(Mdata_raw != 0) <= taxkeepThresh)\n",
    "    if numTaxaNoReads > 0:\n",
    "        Mdata_raw = Mdata_raw.loc[:, colSums(Mdata_raw != 0) > taxkeepThresh]\n",
    "        print(\n",
    "            \"There are \",\n",
    "            numTaxaNoReads,\n",
    "            \" taxa without any sequencing reads before data merging, and excluded from the analysis\",\n",
    "        )\n",
    "    rm(numTaxaNoReads)\n",
    "\n",
    "    numSubNoReads = sum(rowSums(Mdata_raw != 0) <= 1)\n",
    "    if numSubNoReads > 0:\n",
    "        print(\n",
    "            \"There are \",\n",
    "            numSubNoReads,\n",
    "            \" subjects with zero or one sequencing read and excluded from the analysis\",\n",
    "        )\n",
    "        subKeep = inv_bool(rowSums(Mdata_raw != 0) <= 1)\n",
    "        Mdata_raw = Mdata_raw.loc[subKeep, :]\n",
    "        MdataWithId = MdataWithId.loc[subKeep, :]\n",
    "        rm(subKeep)\n",
    "    rm(numSubNoReads)\n",
    "\n",
    "    Mdata = Mdata_raw\n",
    "    rm(Mdata_raw)\n",
    "\n",
    "    microbName1 = colnames(Mdata)\n",
    "    microbName = microbName1\n",
    "    newMicrobNames1 = np.array([\"microb\" + str(i + 1) for i in range(len(microbName))])\n",
    "    newMicrobNames = newMicrobNames1\n",
    "    results[\"Mprefix\"] = \"microb\"\n",
    "    Mdata = Mdata.rename(columns=dict(zip(microbName1, newMicrobNames)))\n",
    "\n",
    "    MdataWithId_new = cbind([MdataWithId.loc[:, linkIDname], Mdata])\n",
    "\n",
    "    results[\"microbName\"] = microbName\n",
    "    results[\"newMicrobNames\"] = newMicrobNames\n",
    "\n",
    "    if Covariates.isna().sum().sum() > 0:\n",
    "        print(\"Samples with missing covariate values are removed from the analysis.\")\n",
    "\n",
    "    ## to add non-numeric add\n",
    "\n",
    "    xNames = colnames(Covariates)\n",
    "    nCov = len(xNames)\n",
    "\n",
    "    ## to add binary check\n",
    "\n",
    "    binCheck = Covariates.nunique()\n",
    "\n",
    "    if any(binCheck == 2):\n",
    "        binaryInd = which(binCheck == 2)\n",
    "        results[\"varNamForBin\"] = xNames[binCheck == 2]\n",
    "        results[\"nBinVars\"] = len(results[\"varNamForBin\"])\n",
    "\n",
    "        for i in range(varNamForBin):\n",
    "            mini = min(Covariates.iloc[:, i])\n",
    "            maxi = max(Covariates.iloc[:, i])\n",
    "            if any(mini != 0 and maxi != 1):\n",
    "                Covariates.iloc[\n",
    "                    Covariates.iloc[:, i] == mini, results[\"varNamForBin\"][i]\n",
    "                ] = 0\n",
    "                Covariates.iloc[\n",
    "                    Covariates.iloc[:, i] == maxi, results[\"varNamForBin\"][i]\n",
    "                ] = 1\n",
    "                print(\n",
    "                    \"Binary covariate\",\n",
    "                    i,\n",
    "                    \"is not coded as 0/1 which may generate analysis bias. It has been changed to 0/1. The changed covariates data can be extracted from the result file.\",\n",
    "                )\n",
    "\n",
    "    results[\"nBinVars\"] = 0\n",
    "    binaryInd = []\n",
    "    results[\"varNamForBin\"] = []\n",
    "\n",
    "    results[\"binaryInd\"] = []\n",
    "    results[\"xNames\"] = colnames(Covariates)\n",
    "    xNewNames = np.array([\"x\" + str(i + 1) for i in range(len(xNames))])\n",
    "    Covariates = Covariates.rename(columns=dict(zip(colnames(Covariates), xNewNames)))\n",
    "    results[\"covsPrefix\"] = \"x\"\n",
    "    results[\"xNewNames\"] = xNewNames\n",
    "\n",
    "    results[\"testCovInd\"] = which(r_in(results[\"xNames\"], testCov))\n",
    "\n",
    "    results[\"testCovInOrder\"] = results[\"xNames\"][results[\"testCovInd\"]]\n",
    "    results[\"testCovInNewNam\"] = results[\"xNewNames\"][results[\"testCovInd\"]]\n",
    "    del (xNames, xNewNames)\n",
    "\n",
    "    CovarWithId_new = cbind([CovarWithId.loc[:, linkIDname], Covariates])\n",
    "    data = MdataWithId_new.merge(CovarWithId_new, on=linkIDname.tolist())\n",
    "    dataOmit = data.dropna()\n",
    "\n",
    "    results[\"covariatesData\"] = CovarWithId_new\n",
    "    results[\"covariatesData\"].rename(\n",
    "        columns=dict(\n",
    "            zip(results[\"covariatesData\"], np.insert(results[\"xNames\"], 0, linkIDname))\n",
    "        )\n",
    "    )\n",
    "    del (MdataWithId_new, CovarWithId_new)\n",
    "\n",
    "    Mdata_omit = dataOmit.loc[:, np.array(newMicrobNames1)]\n",
    "\n",
    "    # check taxa with zero or 1 read again after all missing data removed\n",
    "    # to add\n",
    "\n",
    "    results[\"data\"] = dataOmit\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def dataInfo(\n",
    "    data,\n",
    "    Mprefix,\n",
    "    covsPrefix,\n",
    "    binPredInd,\n",
    "    refReadsThresh=None,\n",
    "    SDThresh=None,\n",
    "    SDquantilThresh=None,\n",
    "    balanceCut=None,\n",
    "    qualifyRefTax=False,\n",
    "):\n",
    "    results = {}\n",
    "\n",
    "    # get the original sample size\n",
    "    nSub = nrow(data)\n",
    "    MVarNamLength = len(Mprefix)\n",
    "\n",
    "    # get taxa variable names\n",
    "    microPositions = data.columns.str.startswith(Mprefix)\n",
    "    nTaxa = len(which(microPositions))\n",
    "    taxaNames = data.columns[microPositions]\n",
    "    rm(microPositions)\n",
    "\n",
    "    ## to add if qualifyreftax\n",
    "    if qualifyRefTax:\n",
    "        qualifyData = data.loc[rowSums(data.loc[:, taxaNames] > 0) >= 2, :]\n",
    "        w = qualifyData.loc[:, taxaNames]\n",
    "        nSubQualif = nrow(qualifyData)\n",
    "        taxaOverThresh = taxaNames[colSums(w > 0) >= (nSubQualif * refReadsThresh)]\n",
    "        if len(taxaOverThresh) == 0:\n",
    "            print(\n",
    "                \"There are no taxa with presence over the threshold:\",\n",
    "                refReadsThresh,\n",
    "                \". Try lower the reference taxa reads threshold.\",\n",
    "                \"\\n\",\n",
    "            )\n",
    "\n",
    "        # check the sd threshold\n",
    "        sdTaxaOverThresh = np.zeros(len(taxaOverThresh))\n",
    "\n",
    "        for i in range(len(taxaOverThresh)):\n",
    "            taxa_i = w.loc[:, taxaOverThresh[i]].to_numpy()\n",
    "            if np.sum(taxa_i > 0) > 1:\n",
    "                sdTaxaOverThresh[i] = np.std(taxa_i[(taxa_i > 0)], ddof=1)\n",
    "\n",
    "        results[\"sdTaxa\"] = sdTaxaOverThresh\n",
    "\n",
    "        TaxaOverSdThresh = taxaOverThresh[(sdTaxaOverThresh >= SDThresh)]\n",
    "        if len(TaxaOverSdThresh) == 0:\n",
    "            print(\n",
    "                \"There are no taxa with SD over the SD threshold:\",\n",
    "                SDThresh,\n",
    "                \". Try lower the SD threshold\",\n",
    "                \"\\n\",\n",
    "            )\n",
    "            rm(taxa_i, taxaOverThresh)\n",
    "\n",
    "        # check the sd quantile threshold\n",
    "\n",
    "        sdAllTaxa = np.zeros(nTaxa)\n",
    "        for i in range(nTaxa):\n",
    "            taxaAll_i = w.loc[:, taxaNames[i]]\n",
    "            posTaxaAll_i = taxaAll_i[(taxaAll_i > 0)]\n",
    "            if len(posTaxaAll_i) > 1:\n",
    "                sdAllTaxa[i] = np.std(posTaxaAll_i, ddof=1)\n",
    "                goodRefTaxaCandi = TaxaOverSdThresh[\n",
    "                    (sdAllTaxa >= np.quantile(sdAllTaxa, SDquantilThresh))\n",
    "                ]\n",
    "                rm(sdAllTaxa, posTaxaAll_i, TaxaOverSdThresh)\n",
    "\n",
    "        if len(goodRefTaxaCandi) == 0:\n",
    "            print(\n",
    "                \"There are no taxa with SD over the SD quantile threshold:\",\n",
    "                SDquantilThresh,\n",
    "                \". Try lower the SD quantile threshold\",\n",
    "                \"\\n\",\n",
    "            )\n",
    "            rm(w)\n",
    "\n",
    "    # get predictor data\n",
    "    predNames = data.columns[data.columns.str.startswith(covsPrefix)].to_numpy()\n",
    "    nPredics = len(predNames)\n",
    "\n",
    "    ## to add if qualifyreftax\n",
    "    if qualifyRefTax:\n",
    "        # find the pairs of binary preds and taxa for which the assocaiton is not identifiable\n",
    "        if len(binPredInd) > 0:\n",
    "            allBinPred = predNames[binPredInd]\n",
    "            nBinPred = len(allBinPred)\n",
    "\n",
    "            taxaBalanceBin = c()\n",
    "            bin_nonz_sum = colSums(qualifyData.loc[:, allBinPred])\n",
    "\n",
    "            if min(bin_nonz_sum, nSubQualif - bin_nonz_sum) <= np.floor(\n",
    "                balanceCut * nSubQualif\n",
    "            ):\n",
    "                raise Exception(\"one of the binary variable is not diverse enough\")\n",
    "\n",
    "            ## to add binary loop\n",
    "            taxaBalanceBin = np.unique(taxaBalanceBin)\n",
    "            # keep balanced taxa\n",
    "            goodRefTaxaCandi = goodRefTaxaCandi[r_in(goodRefTaxaCandi, taxaBalanceBin)]\n",
    "        results[\"goodRefTaxaCandi\"] = goodRefTaxaCandi\n",
    "        rm(goodRefTaxaCandi)\n",
    "\n",
    "    # return\n",
    "    results[\"taxaNames\"] = taxaNames\n",
    "    rm(taxaNames)\n",
    "    results[\"predNames\"] = predNames\n",
    "    rm(predNames)\n",
    "    results[\"nTaxa\"] = nTaxa\n",
    "    results[\"nSub\"] = nSub\n",
    "    results[\"nPredics\"] = nPredics\n",
    "    return results\n",
    "\n",
    "\n",
    "def dataRecovTrans(data, ref, Mprefix, covsPrefix, xOnly=False, yOnly=False):\n",
    "    results = {}\n",
    "\n",
    "    # load A and log-ratio transformed RA\n",
    "    data_and_init = AIcalcu(data=data, ref=ref, Mprefix=Mprefix, covsPrefix=covsPrefix)\n",
    "    rm(data)\n",
    "\n",
    "    taxaNames = data_and_init[\"taxaNames\"]\n",
    "    A = data_and_init[\"A\"]\n",
    "    logRatiow = data_and_init[\"logRatiow\"]\n",
    "    nSub = data_and_init[\"nSub\"]\n",
    "    nTaxa = data_and_init[\"nTaxa\"]\n",
    "    xData = data_and_init[\"xData\"]\n",
    "    nPredics = data_and_init[\"nPredics\"]\n",
    "    twoList = data_and_init[\"twoList\"]\n",
    "    lLast = data_and_init[\"lLast\"]\n",
    "    L = data_and_init[\"l\"]\n",
    "    lengthTwoList = data_and_init[\"lengthTwoList\"]\n",
    "    rm(data_and_init)\n",
    "\n",
    "    nNorm = nTaxa - 1\n",
    "    xDimension = nPredics + 1  # predictors+intercept\n",
    "\n",
    "    # create omegaRoot\n",
    "    omegaRoot = {}\n",
    "    for j in range(lengthTwoList):\n",
    "        i = twoList[j]\n",
    "        if lLast[i] == nTaxa:\n",
    "            omegaRoot[i] = np.eye(int(L[i] - 1))\n",
    "        else:\n",
    "            if L[i] == 2:\n",
    "                omegaRoot[i] = np.sqrt(0.5)\n",
    "            else:\n",
    "                dim = L[i] - 1\n",
    "                a = (1 + (dim - 2) / 2) / (1 / 2 * (1 + (dim - 1) / 2))\n",
    "                b = -1 / (1 + (dim - 1) / 2)\n",
    "\n",
    "                # calculate the square root of omega assuming it is exchangeable\n",
    "                aStar = dim**2 / ((dim - 1) ** 2)\n",
    "                bStar = b * (dim - 2) / (dim - 1) - a * (dim**2 - 2 * dim + 2) / (\n",
    "                    (dim - 1) ** 2\n",
    "                )\n",
    "                cStar = (0.5 * b - 0.5 * a * (dim - 2) / (dim - 1)) ** 2\n",
    "                cSquare = (-bStar + np.sqrt(bStar**2 - 4 * aStar * cStar)) / (\n",
    "                    2 * aStar\n",
    "                )\n",
    "\n",
    "                if cSquare < 0:\n",
    "                    raise Exception(\"no solution for square root of omega\")\n",
    "                d = np.sqrt((0.5 * a - cSquare) / (dim - 1))\n",
    "\n",
    "                if d is None:\n",
    "                    raise Exception(\n",
    "                        \"no solution for off-diagnal elements for square root of omega\"\n",
    "                    )\n",
    "                c = (0.5 * b - (dim - 2) * (d**2)) / (2 * d)\n",
    "                omegaRoot[i] = -(\n",
    "                    (c - d) * np.eye(int(dim)) + d * np.ones((int(dim), int(dim)))\n",
    "                )\n",
    "\n",
    "        rm(L, lLast)\n",
    "\n",
    "    if xOnly:\n",
    "        # create X_i in the regression equation using Kronecker product\n",
    "        xDataWithInter = xData.copy()\n",
    "        xDataWithInter.insert(0, \"Intercept\", 1)\n",
    "        xDataWithInter = xDataWithInter.to_numpy()\n",
    "        rm(xData)\n",
    "\n",
    "        for j in range(lengthTwoList):\n",
    "            i = twoList[j]\n",
    "            xInRegres_i = np.kron(np.eye(nNorm), xDataWithInter[i, :])\n",
    "            xDataTilda_i = omegaRoot[i] @ A[i] @ xInRegres_i\n",
    "            rm(xInRegres_i)\n",
    "\n",
    "            if j == 0:\n",
    "                xTildalong = xDataTilda_i\n",
    "            else:\n",
    "                xTildalong = np.vstack((xTildalong, xDataTilda_i))\n",
    "\n",
    "        rm(xDataWithInter, xDataTilda_i, omegaRoot, logRatiow)\n",
    "\n",
    "        results[\"xTildalong\"] = xTildalong\n",
    "        rm(xTildalong)\n",
    "        return results\n",
    "\n",
    "    if yOnly:\n",
    "        for j in range(lengthTwoList):\n",
    "            i = twoList[j]\n",
    "            Utilda_i = omegaRoot[i] @ logRatiow[i]\n",
    "            if j == 0:\n",
    "                UtildaLong = Utilda_i\n",
    "            else:\n",
    "                UtildaLong = np.hstack((UtildaLong, Utilda_i))\n",
    "\n",
    "        rm(omegaRoot, logRatiow, Utilda.i)\n",
    "        results[\"UtildaLong\"] = UtildaLong\n",
    "        rm(UtildaLong)\n",
    "        return results\n",
    "\n",
    "    # create X_i in the regression equation using Kronecker product\n",
    "    xDataWithInter = xData.copy()\n",
    "    rm(xData)\n",
    "    xDataWithInter.insert(0, \"Inter\", 1)\n",
    "    xDataWithInter = xDataWithInter.to_numpy()\n",
    "\n",
    "    for j in range(lengthTwoList):\n",
    "        i = twoList[j]\n",
    "        xInRegres_i = np.kron(np.eye(nNorm), xDataWithInter[i, :])\n",
    "        xDataTilda_i = omegaRoot[i] @ A[i] @ xInRegres_i\n",
    "        rm(xInRegres_i)\n",
    "\n",
    "        if j == 0:\n",
    "            xTildalong = xDataTilda_i\n",
    "        else:\n",
    "            xTildalong = np.vstack((xTildalong, xDataTilda_i))\n",
    "\n",
    "    rm(xDataWithInter, xDataTilda_i)\n",
    "\n",
    "    for j in range(lengthTwoList):\n",
    "        i = twoList[j]\n",
    "        Utilda_i = omegaRoot[i] @ logRatiow[i]\n",
    "        if j == 0:\n",
    "            UtildaLong = Utilda_i\n",
    "        else:\n",
    "            UtildaLong = np.hstack((UtildaLong, Utilda_i))\n",
    "\n",
    "    rm(omegaRoot, logRatiow, Utilda_i)\n",
    "\n",
    "    # return objects\n",
    "    results[\"UtildaLong\"] = UtildaLong\n",
    "    rm(UtildaLong)\n",
    "    results[\"xTildalong\"] = xTildalong\n",
    "    rm(xTildalong)\n",
    "    results[\"taxaNames\"] = taxaNames\n",
    "    rm(taxaNames)\n",
    "    return results\n",
    "\n",
    "\n",
    "def AIcalcu(data, ref, Mprefix, covsPrefix):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # get the original sample size\n",
    "    nSub = nrow(data)\n",
    "    MVarNamLength = len(Mprefix)\n",
    "\n",
    "    # get taxa variable names\n",
    "    microPositions = data.columns.str.startswith(Mprefix)\n",
    "    nTaxa = len(which(microPositions))\n",
    "    nNorm = nTaxa - 1\n",
    "    taxaNames = data.columns[microPositions]\n",
    "    rm(microPositions)\n",
    "\n",
    "    # rearrange taxa names\n",
    "    otherTaxaNames = taxaNames[r_ni(taxaNames, ref)]\n",
    "    taxaNames = np.hstack([otherTaxaNames, ref])\n",
    "\n",
    "    # get predictor data\n",
    "    predNames = data.columns[data.columns.str.startswith(covsPrefix)].to_numpy()\n",
    "    nPredics = len(predNames)\n",
    "\n",
    "    # taxa data\n",
    "    w = data.loc[:, taxaNames]\n",
    "\n",
    "    # extract x data\n",
    "    xData = data.loc[:, predNames]\n",
    "    rm(data, predNames)\n",
    "\n",
    "    # transform data using log-ratio, creat Ai and Li\n",
    "    l = np.empty(nSub)\n",
    "    lLast = np.empty(nSub)\n",
    "    taxa_non0 = {}\n",
    "    taxa_0 = {}\n",
    "    logRatiow = {}\n",
    "    A = {}\n",
    "\n",
    "    for i in range(nSub):\n",
    "        taxa_nonzero = which(w.iloc[i, :] != 0)\n",
    "        lLast[i] = np.max(taxa_nonzero)\n",
    "        taxa_zero = which(w.iloc[i, :] == 0)\n",
    "        taxa_non0[i] = w.iloc[i, taxa_nonzero]\n",
    "        taxa_0[i] = w.iloc[i, taxa_zero]\n",
    "        if len(taxa_nonzero) > 0:\n",
    "            last_nonzero = np.max(taxa_nonzero)\n",
    "            logwi = np.log(w.iloc[i, taxa_nonzero])\n",
    "            l[i] = len(logwi)\n",
    "            if l[i] > 1:\n",
    "                logRatiow[i] = logwi[:-1:] - logwi[-1]\n",
    "                zero_m = np.zeros((int(l[i]) - 1, nNorm))\n",
    "                if last_nonzero == nTaxa:\n",
    "                    aRow = np.arange(int(l[i]) - 1)\n",
    "                    aCol = taxa_nonzero[:-1:]\n",
    "                    zero_m[aRow, aCol] = 1\n",
    "                else:\n",
    "                    aRow = np.arange(int(l[i]) - 1)\n",
    "                    aCol = taxa_nonzero[:-1:]\n",
    "                    zero_m[aRow, aCol] = 1\n",
    "                    zero_m[:, int(taxa_nonzero[int(l[i]) - 1]) - 1] = -1\n",
    "                    A[i] = zero_m\n",
    "                    rm(zero_m)\n",
    "            else:\n",
    "                logRatiow[i] = None\n",
    "                A[i] = None\n",
    "        else:\n",
    "            l[i] = 0\n",
    "            logRatiow[i] = None\n",
    "            A[i] = None\n",
    "\n",
    "    # obtain the list of samples whose have at least 2 non-zero taxa\n",
    "    twoList = which(l > 1)\n",
    "    lengthTwoList = len(twoList)\n",
    "\n",
    "    rm(w)\n",
    "\n",
    "    results[\"xData\"] = xData\n",
    "    rm(xData)\n",
    "\n",
    "    results[\"logRatiow\"] = logRatiow\n",
    "    rm(logRatiow)\n",
    "    results[\"A\"] = A\n",
    "    rm(A)\n",
    "    results[\"twoList\"] = twoList\n",
    "    rm(twoList)\n",
    "    results[\"taxaNames\"] = taxaNames\n",
    "    rm(taxaNames)\n",
    "    results[\"lengthTwoList\"] = lengthTwoList\n",
    "    results[\"lLast\"] = lLast\n",
    "    results[\"l\"] = l\n",
    "    results[\"nTaxa\"] = nTaxa\n",
    "    results[\"nNorm\"] = nNorm\n",
    "    results[\"nSub\"] = nSub\n",
    "    results[\"nPredics\"] = nPredics\n",
    "    return results\n",
    "\n",
    "\n",
    "def runScrParal(\n",
    "    data,\n",
    "    testCovInd,\n",
    "    testCovInOrder,\n",
    "    testCovInNewNam,\n",
    "    nRef,\n",
    "    paraJobs,\n",
    "    refTaxa,\n",
    "    standardize,\n",
    "    sequentialRun,\n",
    "    refReadsThresh,\n",
    "    SDThresh,\n",
    "    SDquantilThresh,\n",
    "    balanceCut,\n",
    "    Mprefix,\n",
    "    covsPrefix,\n",
    "    binPredInd,\n",
    "    adjust_method,\n",
    "    seed,\n",
    "    maxDimensionScr=0.8 * 434 * 10 * 10**4\n",
    "):\n",
    "    \n",
    "    results={}\n",
    "    \n",
    "    # load data info\n",
    "    basicInfo = dataInfo(\n",
    "        data=data,\n",
    "        Mprefix=Mprefix,\n",
    "        covsPrefix=covsPrefix,\n",
    "        binPredInd=binPredInd,\n",
    "        refReadsThresh=refReadsThresh,\n",
    "        SDThresh=SDThresh,\n",
    "        SDquantilThresh=SDquantilThresh,\n",
    "        balanceCut=balanceCut,\n",
    "        qualifyRefTax=True,\n",
    "    )\n",
    "\n",
    "    taxaNames = basicInfo[\"taxaNames\"]\n",
    "    nTaxa = basicInfo[\"nTaxa\"]\n",
    "    nPredics = basicInfo[\"nPredics\"]\n",
    "    nSub = basicInfo[\"nSub\"]\n",
    "    predNames = basicInfo[\"predNames\"]\n",
    "\n",
    "    results[\"goodRefTaxaCandi\"] = basicInfo[\"goodRefTaxaCandi\"]\n",
    "    rm(basicInfo)\n",
    "\n",
    "    nNorm = nTaxa - 1\n",
    "    nAlphaNoInt = nPredics * nNorm\n",
    "    nAlphaSelec = nPredics * nTaxa\n",
    "\n",
    "    # make reference taxa list\n",
    "    if len(refTaxa) < nRef:\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        taxon_to_be_sample = results[\"goodRefTaxaCandi\"][\n",
    "            r_ni(results[\"goodRefTaxaCandi\"], refTaxa)\n",
    "        ]\n",
    "        num_to_be_sample = nRef - len(refTaxa)\n",
    "\n",
    "        if num_to_be_sample >= len(taxon_to_be_sample):\n",
    "            num_to_be_sample = len(taxon_to_be_sample)\n",
    "        print(\n",
    "            \"The number of candidate reference taxon is smaller than the number of taxon required in phase 1. The number of taxon was set to be \",\n",
    "            num_to_be_sample,\n",
    "        )\n",
    "\n",
    "        refTaxa_extra = np.random.choice(\n",
    "            taxon_to_be_sample, num_to_be_sample, replace=False\n",
    "        )\n",
    "        refTaxa = np.hstack((refTaxa, refTaxa_extra))\n",
    "        results[\"refTaxa\"] = refTaxa\n",
    "\n",
    "        if len(refTaxa) == 0:\n",
    "            raise Exception(\n",
    "                \"No candidate reference taxon is available. Please try to lower the reference taxon boundary.\"\n",
    "            )\n",
    "\n",
    "    if len(refTaxa) >= nRef:\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        refTaxa = np.random.choice(refTaxa, nRef, replace=True)\n",
    "        results[\"refTaxa\"] = refTaxa\n",
    "\n",
    "    ## run original data screen\n",
    "    screen1 = originDataScreen(\n",
    "        data=data,\n",
    "        testCovInd=testCovInd,\n",
    "        nRef=nRef,\n",
    "        refTaxa=refTaxa,\n",
    "        paraJobs=paraJobs,\n",
    "        Mprefix=Mprefix,\n",
    "        covsPrefix=covsPrefix,\n",
    "        binPredInd=binPredInd,\n",
    "        standardize=standardize,\n",
    "        sequentialRun=sequentialRun,\n",
    "        adjust_method=adjust_method,\n",
    "        seed=seed,\n",
    "    )\n",
    "    \n",
    "    results['countOfSelecForAPred']=screen1['countOfSelecForAPred']\n",
    "    results['estOfSelectForAPred']=screen1['estOfSelectForAPred']\n",
    "    results['testCovCountMat']=screen1['testCovCountMat']\n",
    "    results['testEstMat']=screen1['testEstMat']\n",
    "\n",
    "    rm(screen1)\n",
    "\n",
    "    nTestCov=len(testCovInd)\n",
    "    results['nTestCov']=nTestCov\n",
    "    results['nTaxa']=nTaxa\n",
    "    results['nPredics']=nPredics\n",
    "    \n",
    "    results['taxaNames']=taxaNames\n",
    "    rm(taxaNames)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def dataSparsCheck(data, Mprefix):\n",
    "    results = {}\n",
    "\n",
    "    # get the original sample size\n",
    "    nSub = nrow(data)\n",
    "    MVarNamLength = len(Mprefix)\n",
    "\n",
    "    # get taxa variable names\n",
    "    microPositions = data.columns.str.startswith(Mprefix)\n",
    "    taxaNames = data.columns[microPositions]\n",
    "    rm(microPositions)\n",
    "\n",
    "    w = data.loc[:, taxaNames]\n",
    "    rm(data, taxaNames)\n",
    "    overallSparsity = np.round(100 * np.mean(w.values == 0), 2)\n",
    "    print(overallSparsity, \"percent of microbiome sequencing reads are zero\")\n",
    "\n",
    "    # check zero taxa and subjects with zero taxa reads\n",
    "    numTaxaNoReads = sum(colSums(w) == 0)\n",
    "    if numTaxaNoReads > 0:\n",
    "        print(\n",
    "            \"There are \",\n",
    "            numTaxaNoReads,\n",
    "            \" taxa without any sequencing reads and excluded from the analysis\",\n",
    "        )\n",
    "    rm(numTaxaNoReads)\n",
    "\n",
    "    numSubNoReads = sum(rowSums(w) == 0)\n",
    "    if numSubNoReads > 0:\n",
    "        print(\n",
    "            \"There are \",\n",
    "            numSubNoReads,\n",
    "            \" subjects without any sequencing reads and excluded from the analysis.\",\n",
    "        )\n",
    "    rm(numSubNoReads, w)\n",
    "\n",
    "\n",
    "def Regulariz(\n",
    "    data,\n",
    "    testCovInd,\n",
    "    testCovInOrder,\n",
    "    testCovInNewNam,\n",
    "    microbName,\n",
    "    nRef,\n",
    "    nRefMaxForEsti,\n",
    "    refTaxa,\n",
    "    paraJobs,\n",
    "    binaryInd,\n",
    "    covsPrefix,\n",
    "    Mprefix,\n",
    "    fwerRate,\n",
    "    bootB,\n",
    "    standardize,\n",
    "    sequentialRun,\n",
    "    refReadsThresh,\n",
    "    SDThresh,\n",
    "    SDquantilThresh,\n",
    "    balanceCut,\n",
    "    adjust_method,\n",
    "    seed\n",
    "):\n",
    "    results = {}\n",
    "    regul_start_time = timeit.default_timer()\n",
    "\n",
    "    nTestCov = len(testCovInd)\n",
    "    dataSparsCheck(data=data, Mprefix=Mprefix)\n",
    "\n",
    "    # load abundance data info\n",
    "\n",
    "    binCheck = data.loc[:, testCovInNewNam].nunique()\n",
    "    binaryInd = which(binCheck == 2)\n",
    "\n",
    "    data.info = dataInfo(\n",
    "        data=data, Mprefix=Mprefix, covsPrefix=covsPrefix, binPredInd=binaryInd\n",
    "    )\n",
    "    nSub = data.info[\"nSub\"]\n",
    "    taxaNames = data.info[\"taxaNames\"]\n",
    "    nPredics = data.info[\"nPredics\"]\n",
    "    nTaxa = data.info[\"nTaxa\"]\n",
    "    rm(data.info)\n",
    "\n",
    "    regul_start_time = timeit.default_timer()\n",
    "    print(\"Start Phase 1 analysis\")\n",
    "\n",
    "    selectRegroup = getScrResu(\n",
    "        data=data,\n",
    "        testCovInd=testCovInd,\n",
    "        testCovInOrder=testCovInOrder,\n",
    "        testCovInNewNam=testCovInNewNam,\n",
    "        nRef=nRef,\n",
    "        paraJobs=paraJobs,\n",
    "        refTaxa=refTaxa,\n",
    "        standardize=standardize,\n",
    "        sequentialRun=sequentialRun,\n",
    "        refReadsThresh=refReadsThresh,\n",
    "        SDThresh=SDThresh,\n",
    "        SDquantilThresh=SDquantilThresh,\n",
    "        balanceCut=balanceCut,\n",
    "        Mprefix=Mprefix,\n",
    "        covsPrefix=covsPrefix,\n",
    "        binPredInd=binaryInd,\n",
    "        adjust_method=adjust_method,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "\n",
    "def getScrResu(\n",
    "    data,\n",
    "    testCovInd,\n",
    "    testCovInOrder,\n",
    "    testCovInNewNam,\n",
    "    nRef,\n",
    "    paraJobs,\n",
    "    refTaxa,\n",
    "    standardize,\n",
    "    sequentialRun,\n",
    "    refReadsThresh,\n",
    "    SDThresh,\n",
    "    SDquantilThresh,\n",
    "    balanceCut,\n",
    "    Mprefix,\n",
    "    covsPrefix,\n",
    "    binPredInd,\n",
    "    adjust_method,\n",
    "    seed,\n",
    "    goodIndeCutPerc=0.33\n",
    "):\n",
    "    results = {}\n",
    "\n",
    "    # run permutation\n",
    "    scrParal = runScrParal(\n",
    "        data=data,\n",
    "        testCovInd=testCovInd,\n",
    "        testCovInOrder=testCovInOrder,\n",
    "        testCovInNewNam=testCovInNewNam,\n",
    "        nRef=nRef,\n",
    "        paraJobs=paraJobs,\n",
    "        refTaxa=refTaxa,\n",
    "        standardize=standardize,\n",
    "        sequentialRun=sequentialRun,\n",
    "        refReadsThresh=refReadsThresh,\n",
    "        SDThresh=SDThresh,\n",
    "        SDquantilThresh=SDquantilThresh,\n",
    "        balanceCut=balanceCut,\n",
    "        Mprefix=Mprefix,\n",
    "        covsPrefix=covsPrefix,\n",
    "        binPredInd=binPredInd,\n",
    "        adjust_method=adjust_method,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    selecCountOverall = scrParal[\"countOfSelecForAPred\"]\n",
    "    selecEstOverall = scrParal[\"estOfSelectForAPred\"]\n",
    "\n",
    "    selecCountMatIndv = scrParal[\"testCovCountMat\"]\n",
    "    selecEstMatIndv = scrParal[\"testEstMat\"]\n",
    "\n",
    "    taxaNames = scrParal[\"taxaNames\"]\n",
    "    goodRefTaxaCandi = scrParal[\"goodRefTaxaCandi\"]\n",
    "\n",
    "    nTaxa = scrParal[\"nTaxa\"]\n",
    "    nPredics = scrParal[\"nPredics\"]\n",
    "    nTestCov = scrParal[\"nTestCov\"]\n",
    "    results[\"refTaxa\"] = scrParal[\"refTaxa\"]\n",
    "    rm(scrParal)\n",
    "\n",
    "    if nTestCov == 1:\n",
    "        results[\"selecCountMatIndv\"] = selecCountOverall\n",
    "        results[\"selecEstMatIndv\"] = selecEstOverall\n",
    "    if nTestCov > 1:\n",
    "        results[\"selecCountMatIndv\"] = selecCountMatIndv\n",
    "        results[\"selecEstMatIndv\"] = selecEstMatIndv\n",
    "        rm(selecCountMatIndv)\n",
    "    breakpoint()\n",
    "\n",
    "    goodIndpRefTaxWithCount = selecCountOverall.iloc[\n",
    "        0, r_in(colnames(selecCountOverall), goodRefTaxaCandi)\n",
    "    ]\n",
    "    goodIndpRefTaxWithEst = selecEstOverall.iloc[\n",
    "        0, r_in(colnames(selecEstOverall), goodRefTaxaCandi)\n",
    "    ]\n",
    "\n",
    "    if len(goodIndpRefTaxWithCount) == 0:\n",
    "        results[\"goodIndpRefTaxLeastCount\"] = np.array([])\n",
    "    else:\n",
    "        goodIndpRefTaxWithCount.index\n",
    "        \n",
    "        \n",
    "        results['goodIndpRefTaxLeastCount']=names()[order(goodIndpRefTaxWithCount,abs(goodIndpRefTaxWithEst))][1:2]\n",
    "        goodIndpRefTaxWithEst<-abs(goodIndpRefTaxWithEst[order(goodIndpRefTaxWithCount,abs(goodIndpRefTaxWithEst))])\n",
    "        goodIndpRefTaxWithCount<-goodIndpRefTaxWithCount[order(goodIndpRefTaxWithCount,abs(goodIndpRefTaxWithEst))]\n",
    "    \n",
    "    \n",
    "    \n",
    "    results[\"selecCountOverall\"] = selecCountOverall\n",
    "    results[\"goodIndpRefTaxWithCount\"] = goodIndpRefTaxWithCount\n",
    "    results[\"goodIndpRefTaxWithEst\"] = goodIndpRefTaxWithEst\n",
    "    results[\"goodRefTaxaCandi\"] = goodRefTaxaCandi\n",
    "    rm(goodRefTaxaCandi)\n",
    "    results[\"refTaxonQualified\"] = 2\n",
    "    results[\"finalIndpRefTax\"] = results[\"goodIndpRefTaxLeastCount\"]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def originDataScreen(\n",
    "    data,\n",
    "    testCovInd,\n",
    "    nRef,\n",
    "    paraJobs,\n",
    "    refTaxa,\n",
    "    standardize,\n",
    "    sequentialRun,\n",
    "    Mprefix,\n",
    "    covsPrefix,\n",
    "    binPredInd,\n",
    "    adjust_method,\n",
    "    seed,\n",
    "    maxDimensionScr=434 * 5 * 10**5,\n",
    "):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # load data info\n",
    "    basicInfo = dataInfo(\n",
    "        data=data, Mprefix=Mprefix, covsPrefix=covsPrefix, binPredInd=binPredInd\n",
    "    )\n",
    "\n",
    "    taxaNames = basicInfo[\"taxaNames\"]\n",
    "    nTaxa = basicInfo[\"nTaxa\"]\n",
    "    nPredics = basicInfo[\"nPredics\"]\n",
    "    rm(basicInfo)\n",
    "\n",
    "    nNorm = nTaxa - 1\n",
    "    nAlphaNoInt = nPredics * nNorm\n",
    "    nAlphaSelec = nPredics * nTaxa\n",
    "\n",
    "    countOfSelec = np.zeros(nAlphaSelec)\n",
    "\n",
    "    # overwrite nRef if the reference taxon is specified\n",
    "    nRef = len(refTaxa)\n",
    "    \n",
    "    forEachUnitRun_partial = partial(forEachUnitRun, \n",
    "                                     taxaNames,\n",
    "                                     refTaxa,\n",
    "                                     Mprefix,\n",
    "                                     covsPrefix,\n",
    "                                     maxDimensionScr,\n",
    "                                     nPredics,\n",
    "                                     data,\n",
    "                                     nAlphaSelec,\n",
    "                                     nAlphaNoInt,\n",
    "                                     nTaxa)\n",
    "    \n",
    "    startT1 = timeit.default_timer()\n",
    "    if len(paraJobs) == 0:\n",
    "        availCores = mp.cpu_count()\n",
    "        if isinstance(availCores, int):\n",
    "            paraJobs = max(1, availCores - 2)\n",
    "\n",
    "    if not sequentialRun:\n",
    "        print(\n",
    "            paraJobs,\n",
    "            \" parallel jobs are registered for analyzing \",\n",
    "            nRef,\n",
    "            \" reference taxa in Phase 1\",\n",
    "        )\n",
    "        scr1Resu = Parallel(n_jobs=paraJobs, \n",
    "                            require='sharedmem')(delayed(forEachUnitRun_partial)(i) for i in range(nRef))\n",
    "    \n",
    "    if sequentialRun:\n",
    "        print(\n",
    "            \" Sequential running analysis for \",\n",
    "            nRef,\n",
    "            \" reference taxa in Phase 1\",\n",
    "        )\n",
    "        scr1Resu = [ forEachUnitRun_partial(i) for i in range(nRef) ]\n",
    "    \n",
    "    endT = timeit.default_timer()\n",
    "\n",
    "    scr1ResuSelec = np.hstack([i[\"selection\"][:, np.newaxis] for i in scr1Resu])\n",
    "    scr1ResuEst = np.hstack([i[\"coef\"][:, np.newaxis] for i in scr1Resu])\n",
    "\n",
    "    # create count of selection for individual testCov\n",
    "    countOfSelecForAllPred = scr1ResuSelec.sum(axis=1).reshape((nPredics, -1))\n",
    "    EstOfAllPred = scr1ResuEst.sum(axis=1).reshape((nPredics, -1))\n",
    "\n",
    "    testCovCountMat = countOfSelecForAllPred[\n",
    "        testCovInd,\n",
    "    ]\n",
    "    testEstMat = EstOfAllPred[\n",
    "        testCovInd,\n",
    "    ]\n",
    "    rm(scr1ResuSelec, testCovInd, countOfSelecForAllPred, EstOfAllPred)\n",
    "\n",
    "    # create overall count of selection for all testCov as a whole\n",
    "    countOfSelecForAPred = testCovCountMat.sum(axis=0).reshape((1, -1))\n",
    "    estOfSelectForAPred = testEstMat.sum(axis=0).reshape((1, -1))\n",
    "\n",
    "    countOfSelecForAPred = pd.DataFrame(countOfSelecForAPred)\n",
    "    estOfSelectForAPred = pd.DataFrame(estOfSelectForAPred)\n",
    "\n",
    "    countOfSelecForAPred.columns = taxaNames\n",
    "    estOfSelectForAPred.columns = taxaNames\n",
    "\n",
    "    # return results\n",
    "    results[\"testCovCountMat\"] = testCovCountMat\n",
    "    results[\"testEstMat\"] = testEstMat\n",
    "    rm(testCovCountMat, testEstMat)\n",
    "    results[\"countOfSelecForAPred\"] = countOfSelecForAPred\n",
    "    results[\"estOfSelectForAPred\"] = estOfSelectForAPred\n",
    "    rm(countOfSelecForAPred, estOfSelectForAPred)\n",
    "    return results\n",
    "\n",
    "\n",
    "def forEachUnitRun(taxaNames, \n",
    "                   refTaxa,\n",
    "                   Mprefix,\n",
    "                   covsPrefix,\n",
    "                   maxDimensionScr,\n",
    "                   nPredics,\n",
    "                   data,\n",
    "                   nAlphaSelec,\n",
    "                   nAlphaNoInt,\n",
    "                   nTaxa,\n",
    "                   i):\n",
    "\n",
    "    ii = which(taxaNames == refTaxa[i])\n",
    "    dataForEst = dataRecovTrans(\n",
    "        data=data, ref=refTaxa[i], Mprefix=Mprefix, covsPrefix=covsPrefix\n",
    "    )\n",
    "\n",
    "    xTildLongTild_i = dataForEst[\"xTildalong\"]\n",
    "    yTildLongTild_i = dataForEst[\"UtildaLong\"]\n",
    "    rm(dataForEst)\n",
    "\n",
    "    maxSubSamplSiz = np.min(\n",
    "        (50000.0, np.floor(maxDimensionScr / xTildLongTild_i.shape[1]))\n",
    "    ).astype(int)\n",
    "\n",
    "    nToSamplFrom = xTildLongTild_i.shape[0]\n",
    "\n",
    "    subSamplK = np.ceil(nToSamplFrom / maxSubSamplSiz).astype(int)\n",
    "\n",
    "    if subSamplK == 1:\n",
    "        maxSubSamplSiz = nToSamplFrom\n",
    "\n",
    "    nRuns = np.ceil(subSamplK / 3).astype(int)\n",
    "\n",
    "    for k in range(nRuns):\n",
    "        rowToKeep = np.random.choice(nToSamplFrom, maxSubSamplSiz, replace=False)\n",
    "\n",
    "        x = xTildLongTild_i[rowToKeep, :]\n",
    "        y = yTildLongTild_i[rowToKeep]\n",
    "\n",
    "        if x.shape[0] > (3 * x.shape[1]):\n",
    "            Penal_i = runlinear(x=x, y=y, nPredics=nPredics)\n",
    "            BetaNoInt_k = (Penal_i[\"betaNoInt\"] != 0).astype(int)\n",
    "            EstNoInt_k = np.abs(Penal_i[\"coef_est_noint\"])\n",
    "        else:\n",
    "            Penal_i = runGlmnet(x=x, y=y, nPredics=nPredics, standardize=standardize)\n",
    "            BetaNoInt_k = (Penal_i[\"betaNoInt\"] != 0).astype(int)\n",
    "            EstNoInt_k = np.abs(Penal_i[\"betaNoInt\"])\n",
    "\n",
    "        rm(Penal_i)\n",
    "        if k == 0:\n",
    "            BetaNoInt_i = BetaNoInt_k\n",
    "            EstNoInt_i = EstNoInt_k\n",
    "        if k > 0:\n",
    "            BetaNoInt_i = BetaNoInt_i + BetaNoInt_k\n",
    "            EstNoInt_i = EstNoInt_i + EstNoInt_k\n",
    "        rm(BetaNoInt_k, EstNoInt_k)\n",
    "\n",
    "    rm(k, x, y, xTildLongTild_i)\n",
    "    BetaNoInt_i = BetaNoInt_i / nRuns\n",
    "    EstNoInt_i = EstNoInt_i / nRuns\n",
    "    selection_i = np.zeros(nAlphaSelec)\n",
    "    coef_i = np.zeros(nAlphaSelec)\n",
    "    if ii == 1:\n",
    "        np_assign_but(selection_i, np.linspace(0, nPredics - 1, nPredics), BetaNoInt_i)\n",
    "        np_assign_but(coef_i, np.linspace(0, nPredics - 1, nPredics), EstNoInt_i)\n",
    "    if ii == nTaxa:\n",
    "        np_assign_but(\n",
    "            selection_i,\n",
    "            np.linspace(nAlphaSelec - nPredics + 1, nAlphaSelec, nPredics),\n",
    "            BetaNoInt_i,\n",
    "        )\n",
    "        np_assign_but(\n",
    "            coef_i,\n",
    "            np.linspace(nAlphaSelec - nPredics + 1, nAlphaSelec, nPredics),\n",
    "            EstNoInt_i,\n",
    "        )\n",
    "    if (ii > 1) & (ii < nTaxa):\n",
    "        selection_i[0 : int((nPredics * (ii - 1)))] = BetaNoInt_i[\n",
    "            0 : int((nPredics * (ii - 1)))\n",
    "        ]\n",
    "        selection_i[int(nPredics * (ii - 1)) : nAlphaNoInt] = BetaNoInt_i[\n",
    "            int(nPredics * (ii - 1)) : nAlphaNoInt\n",
    "        ]\n",
    "        coef_i[0 : int((nPredics * (ii - 1)))] = EstNoInt_i[\n",
    "            0 : int((nPredics * (ii - 1)))\n",
    "        ]\n",
    "        coef_i[int(nPredics * (ii - 1)) : nAlphaNoInt] = EstNoInt_i[\n",
    "            int(nPredics * (ii - 1)) : nAlphaNoInt\n",
    "        ]\n",
    "    rm(BetaNoInt_i)\n",
    "    # create return vector\n",
    "    recturnlist = {}\n",
    "    recturnlist[\"selection\"] = selection_i\n",
    "    recturnlist[\"coef\"] = coef_i\n",
    "    return recturnlist\n",
    "\n",
    "\n",
    "def runlinear(x, y, nPredics, fwerRate=0.25, adjust_method=\"fdr_by\"):\n",
    "\n",
    "    x, y = np.array(x), np.array(y)\n",
    "\n",
    "    results = {}\n",
    "    nBeta = x.shape[1]\n",
    "    nObsAll = len(y)\n",
    "    print(\"length of y: \", len(y))\n",
    "\n",
    "    # lm_model = LinearRegression(fit_intercept = False)\n",
    "    # lm_res = lm_model.fit(x, y)\n",
    "    # lm_res.coef_\n",
    "\n",
    "    lm_res = OLS(y, x).fit()\n",
    "    p_value_est = lm_res.pvalues\n",
    "    disc_index = np.arange(0, len(p_value_est), (nPredics + 1))\n",
    "    p_value_est_noint = np.delete(p_value_est, disc_index, axis=0)\n",
    "\n",
    "    ## this method automatically convert over 1 values to 1\n",
    "    p_value_est_noint_adj = multipletests(\n",
    "        p_value_est_noint, alpha=0.05, method=adjust_method\n",
    "    )[1]\n",
    "\n",
    "    coef_est = np.abs(lm_res.params)\n",
    "    disc_index = np.arange(0, len(p_value_est), (nPredics + 1))\n",
    "    ## NA coef is snot considered here\n",
    "    coef_est_noint = np.delete(coef_est, disc_index, axis=0)\n",
    "\n",
    "    # return\n",
    "    results[\"betaNoInt\"] = p_value_est_noint_adj < fwerRate\n",
    "    results[\"betaInt\"] = p_value_est\n",
    "    results[\"coef_est_noint\"] = coef_est_noint\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def runGlmnet(\n",
    "    x,\n",
    "    y,\n",
    "    nPredics,\n",
    "    standardize=False,\n",
    "    family=\"gaussian\",\n",
    "    nfolds=10,\n",
    "    lambda_min_ratio=0.05,\n",
    "    nLam=100,\n",
    "    intercept=True,\n",
    "    zeroSDCut=10 ** (-20),\n",
    "):\n",
    "\n",
    "    results = {}\n",
    "    nBeta = x.shape[1]\n",
    "    nObsAll = len(y)\n",
    "\n",
    "    # remove near constant x columns\n",
    "    sdX = np.std(x, axis=0)\n",
    "    xWithNearZeroSd = which(sdX <= zeroSDCut)\n",
    "    if len(xWithNearZeroSd) > 0:\n",
    "        x = np.delete(x, xWithNearZeroSd, axis=1)\n",
    "    rm(sdX)\n",
    "\n",
    "    # calculate lambda max\n",
    "    if family == \"gaussian\":\n",
    "        lamMax = np.max(np.abs((x * y[:, np.newaxis]).sum(0))) / nObsAll\n",
    "\n",
    "    lamVec = np.linspace(lamMax, 0, nLam + 1)[0:nLam]\n",
    "    if standardize is True:\n",
    "        scaler = StandardScaler()\n",
    "        x = scaler.fit_transform(x)\n",
    "\n",
    "    cvStartTime = timeit.default_timer()\n",
    "    cvStartTimei = timeit.default_timer()\n",
    "\n",
    "    cvResul = LassoCV(\n",
    "        alphas=lamVec, fit_intercept=intercept, cv=nfolds, n_jobs=-1, selection=\"random\"\n",
    "    ).fit(x, y)\n",
    "    lamOpi = cvResul.alpha_\n",
    "\n",
    "    cvExeTimei = (timeit.default_timer() - cvStartTimei) / 60\n",
    "    cvAllTime = (timeit.default_timer() - cvStartTime) / 60\n",
    "\n",
    "    finalLassoRun = Lasso(alpha=lamOpi, fit_intercept=intercept).fit(x, y)\n",
    "\n",
    "    finalLassoRunBeta = finalLassoRun.coef_\n",
    "\n",
    "    finalLassoRunBeta\n",
    "\n",
    "    # convert back to the full beta if there near constant x columns\n",
    "    if len(xWithNearZeroSd) > 0:\n",
    "        pass\n",
    "    else:\n",
    "        beta = finalLassoRunBeta\n",
    "\n",
    "    disc_index = np.arange(0, len(beta), (nPredics + 1))\n",
    "    results[\"betaNoInt\"] = np.delete(beta, disc_index, axis=0)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d787a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Can't perform this operation for loaders without 'get_data()'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rb/tmyfwg8n51d5yfyb1vv_hvsr0000gn/T/ipykernel_64964/3401652216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_dataM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/rb/tmyfwg8n51d5yfyb1vv_hvsr0000gn/T/ipykernel_64964/3532765237.py\u001b[0m in \u001b[0;36mload_dataM\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# This is a stream-like object. If you want the actual info, call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# stream.read()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IFAA/data/dataM.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresource_stream\u001b[0;34m(self, package_or_requirement, resource_name)\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresource_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_or_requirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;34m\"\"\"Return a readable file-like object for specified resource\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         return get_provider(package_or_requirement).get_resource_stream(\n\u001b[0m\u001b[1;32m   1137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_resource_stream\u001b[0;34m(self, manager, resource_name)\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_resource_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resource_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_resource_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_resource_string\u001b[0;34m(self, manager, resource_name)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_resource_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m         raise NotImplementedError(\n\u001b[0m\u001b[1;32m   1557\u001b[0m             \u001b[0;34m\"Can't perform this operation for loaders without 'get_data()'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m         )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Can't perform this operation for loaders without 'get_data()'"
     ]
    }
   ],
   "source": [
    "load_dataM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
